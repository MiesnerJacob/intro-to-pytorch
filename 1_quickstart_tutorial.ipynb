{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "quickstart_tutorial.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6yiH2jkSqyx",
        "outputId": "f7f5185a-0492-4602-97e5-983daa68b149",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiDV8gsFRWa1"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuGaNZXaRWa3"
      },
      "source": [
        "Pytorch has two different data objects:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXzxdD3YRWa4"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J5cvv1fRWa4"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as [TorchText](https://pytorch.org/text/stable/index.html), [TorchVision](https://pytorch.org/vision/stable/index.html), and [TorchAudio](https://pytorch.org/audio/stable/index.html), all of which include datasets. For this tutorial, we will be using a TorchVision dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmWInvT7RWa4"
      },
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "  root='data',\n",
        "  train=True, #False for test dataset\n",
        "  download=True,\n",
        "  transform=ToTensor())\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "  root='data',\n",
        "  train=False, #False for test dataset\n",
        "  download=True,\n",
        "  transform=ToTensor())"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzMEuNkZRWa5"
      },
      "source": [
        "We pass the Dataset as an argument to DataLoader to that wraps an iterable over the dataset, and supports automatic batching, sampling, shuffling, and multiprocess data loading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGYn52NZRWa5",
        "outputId": "39ad08e0-f48a-452b-bcb4-3d9b36797f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "  print(\"Shape of y: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uS04qFNRWa6"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhauQZgWRWa7"
      },
      "source": [
        "To create a neural net in Pytorch you need to create a class that inherits the nn.Module object. You then define layers in the init function and create a function for the forward pass through the network. You can also put the model on GPU is you have one to use:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4KcuNI1RWa7",
        "outputId": "e4d49b9d-2da4-44f6-8974-7fc873f95b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class JacobsPytorchNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(JacobsPytorchNN, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.network_architecture = nn.Sequential(\n",
        "      nn.Linear(28*28,512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,10),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "\t\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.network_architecture(x)\n",
        "    return logits\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "  \n",
        "model = JacobsPytorchNN().to(device)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZjLlOXARWa7"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPu-kX9CRWa8"
      },
      "source": [
        "To train we need a loss function and optimizer algo:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psesC91YRWa8"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AocwJQ29RWa8"
      },
      "source": [
        "First we need to define a training loop & a evaluation function to get eval metric on test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTEjwwDbRWa8"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    \n",
        "    # Compute Loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "    \n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "      \n",
        "def evaluation(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNjp1IRrRWa9"
      },
      "source": [
        "Next we write our training loop using the functions above:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xd6LS8MRWa9",
        "outputId": "354b36d7-077f-4dfc-df44-94d5246bebf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_epochs = 5\n",
        "for i in range(num_epochs):\n",
        "  print(f\"Epoch {i+1}\\n------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  evaluation(test_dataloader, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "------------------------\n",
            "loss: 2.305695  [    0/60000]\n",
            "loss: 1.934930  [ 6400/60000]\n",
            "loss: 1.557467  [12800/60000]\n",
            "loss: 1.686610  [19200/60000]\n",
            "loss: 1.184716  [25600/60000]\n",
            "loss: 1.160299  [32000/60000]\n",
            "loss: 1.193254  [38400/60000]\n",
            "loss: 1.170361  [44800/60000]\n",
            "loss: 1.193878  [51200/60000]\n",
            "loss: 1.035588  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 3514.0%, Avg loss: 1.170203 \n",
            "\n",
            "Epoch 2\n",
            "------------------------\n",
            "loss: 0.995368  [    0/60000]\n",
            "loss: 1.153615  [ 6400/60000]\n",
            "loss: 1.084735  [12800/60000]\n",
            "loss: 1.469074  [19200/60000]\n",
            "loss: 1.037707  [25600/60000]\n",
            "loss: 1.038368  [32000/60000]\n",
            "loss: 1.074881  [38400/60000]\n",
            "loss: 1.143590  [44800/60000]\n",
            "loss: 1.129074  [51200/60000]\n",
            "loss: 0.925802  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 3628.7%, Avg loss: 1.105228 \n",
            "\n",
            "Epoch 3\n",
            "------------------------\n",
            "loss: 0.892823  [    0/60000]\n",
            "loss: 1.062170  [ 6400/60000]\n",
            "loss: 1.023252  [12800/60000]\n",
            "loss: 1.400670  [19200/60000]\n",
            "loss: 0.987280  [25600/60000]\n",
            "loss: 1.009968  [32000/60000]\n",
            "loss: 1.035814  [38400/60000]\n",
            "loss: 1.114178  [44800/60000]\n",
            "loss: 1.090486  [51200/60000]\n",
            "loss: 0.899519  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 3674.5%, Avg loss: 1.078584 \n",
            "\n",
            "Epoch 4\n",
            "------------------------\n",
            "loss: 0.854712  [    0/60000]\n",
            "loss: 1.028149  [ 6400/60000]\n",
            "loss: 0.996587  [12800/60000]\n",
            "loss: 1.368286  [19200/60000]\n",
            "loss: 0.956828  [25600/60000]\n",
            "loss: 0.996644  [32000/60000]\n",
            "loss: 1.001837  [38400/60000]\n",
            "loss: 1.090143  [44800/60000]\n",
            "loss: 1.060828  [51200/60000]\n",
            "loss: 0.888310  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 3694.9%, Avg loss: 1.062067 \n",
            "\n",
            "Epoch 5\n",
            "------------------------\n",
            "loss: 0.831864  [    0/60000]\n",
            "loss: 1.004761  [ 6400/60000]\n",
            "loss: 0.982703  [12800/60000]\n",
            "loss: 1.346223  [19200/60000]\n",
            "loss: 0.935528  [25600/60000]\n",
            "loss: 0.983417  [32000/60000]\n",
            "loss: 0.979823  [38400/60000]\n",
            "loss: 1.075561  [44800/60000]\n",
            "loss: 1.041244  [51200/60000]\n",
            "loss: 0.884984  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 3725.5%, Avg loss: 1.049974 \n",
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_knT-VplRWa-"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQarMf7tRWa-"
      },
      "source": [
        "Loading & Saving Models\n",
        "-------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TRB3-zYSVj8"
      },
      "source": [
        "Loading models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCVsSk_GRWa-",
        "outputId": "6d62eb05-2817-42c0-adf3-d46ea3b1706e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = JacobsPytorchNN()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylQ1dO5HSZG4"
      },
      "source": [
        "Saving models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PII8yUmSZZB",
        "outputId": "37b7d647-7b32-40e6-8352-6623bc431c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved Pytorch Model State to model.pth\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved Pytorch Model State to model.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbrRlElRWa-"
      },
      "source": [
        "Inference\n",
        "----------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtMhdyM_RWa-"
      },
      "source": [
        "Making predictions on one new sample:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnkVxuIRWa-",
        "outputId": "51824ee9-3641-4447-980d-9345e582a79f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}